{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 — Test data pipeline (download → raw → processed)\n",
        "\n",
        "This notebook validates your two scripts:\n",
        "- `load_existing_dataset.py` → downloads GSM8K and writes **raw** JSON into `gsm8k-distillation/data/raw`\n",
        "- `import_data.py` → reads raw JSON and writes **processed** JSON into `gsm8k-distillation/data/processed`\n",
        "\n",
        "Run it from the repo root.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Adjust if your repo root differs\n",
        "REPO_ROOT = Path('.').resolve()\n",
        "RAW_DIR = REPO_ROOT / 'gsm8k-distillation' / 'data' / 'raw'\n",
        "PROCESSED_DIR = REPO_ROOT / 'gsm8k-distillation' / 'data' / 'processed'\n",
        "print('Repo root:', REPO_ROOT)\n",
        "print('RAW_DIR:', RAW_DIR)\n",
        "print('PROCESSED_DIR:', PROCESSED_DIR)\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
        "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If your scripts live in src/data, import them from there.\n",
        "# If needed, extend sys.path to include src.\n",
        "import sys\n",
        "src_path = (REPO_ROOT / 'src').as_posix()\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "from data.load_existing_dataset import GSM8KDatasetProcessor as RawProcessor\n",
        "from data.import_data import GSM8KDatasetLoader as ProcessedLoader\n",
        "\n",
        "print('Imports OK')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "processor = RawProcessor(base_path=RAW_DIR.as_posix())\n",
        "\n",
        "# Download only if missing (avoid re-downloading)\n",
        "raw_train = RAW_DIR / 'gsm8k_cot_train.json'\n",
        "raw_test  = RAW_DIR / 'gsm8k_cot_test.json'\n",
        "\n",
        "if raw_train.exists() and raw_test.exists():\n",
        "    print('Raw files already exist — skipping download.')\n",
        "else:\n",
        "    print('Downloading GSM8K → raw JSON...')\n",
        "    processor.download_and_prepare_gsm8k()\n",
        "    print('Done')\n",
        "\n",
        "print('Raw train exists:', raw_train.exists(), 'size:', raw_train.stat().st_size if raw_train.exists() else None)\n",
        "print('Raw test  exists:', raw_test.exists(),  'size:', raw_test.stat().st_size  if raw_test.exists()  else None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick sanity check: load a few raw records\n",
        "import json\n",
        "\n",
        "def peek_json(path, n=3):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    print('Rows:', len(data))\n",
        "    for i, ex in enumerate(data[:n]):\n",
        "        print('\\n--- Example', i, '---')\n",
        "        print('question:', ex.get('question','')[:120])\n",
        "        print('reasoning:', ex.get('reasoning','')[:120])\n",
        "        print('answer:', ex.get('answer'))\n",
        "\n",
        "if raw_train.exists():\n",
        "    peek_json(raw_train, n=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process: raw → processed\n",
        "\n",
        "train_loader = ProcessedLoader(raw_train)\n",
        "test_loader  = ProcessedLoader(raw_test)\n",
        "\n",
        "train_loader.print_statistics()\n",
        "test_loader.print_statistics()\n",
        "\n",
        "processed_train = PROCESSED_DIR / 'gsm8k_train_processed.json'\n",
        "processed_test  = PROCESSED_DIR / 'gsm8k_test_processed.json'\n",
        "\n",
        "train_loader.save_processed_dataset(train_loader.examples, processed_train)\n",
        "test_loader.save_processed_dataset(test_loader.examples, processed_test)\n",
        "\n",
        "print('Processed train:', processed_train, processed_train.exists(), processed_train.stat().st_size)\n",
        "print('Processed test :', processed_test,  processed_test.exists(),  processed_test.stat().st_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final validation: schema and a couple of rows\n",
        "peek_json(processed_train, n=2)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
